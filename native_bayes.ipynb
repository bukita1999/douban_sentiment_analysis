{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install jieba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Building prefix dict from the default dictionary ...\n",
      "Dumping model to file cache /tmp/jieba.cache\n",
      "Loading model cost 0.909 seconds.\n",
      "Prefix dict has been built successfully.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['非常认同这个评论：傻逼右翼政治宣传电影如果中国人说他经典，我只能说你太装逼', '我是少數覺得很無聊的人', '虽然没有漫画好 还是看得很感动！>皿<。', '一气呵成地看完，太帅了！', '憋死了，憋死了，不好看！我最懒得想象一千年或两千年后世界怎么样·最懒得管你的真爱会不会变成刻在玄武岩上的楔形文字·总之你没有办法用旷日持久的时间打败我，如果你爱我，我只要一百年。不过这是题外。', '小清新，一步难一步佳，日子一样过。', '所以他值9.2的原因是？？我看不懂', '人生全靠政治正确', '其实感觉不是非常非常的感动，对于青年时期的描述有点浮于表面但是演得不错，对老年时期的刻画有点诡异，那句Your Mother is My Home 就显得造作了。时长放在那儿，总体不错。我在思考，要是当年是BS演了Alie，是不是歌坛就少了个女王陛下？！@Home', '青春的银幕会有不同的人出场，共同经历一些事，一起走过很多地方。伴随着成长，有些人离去了，即使短暂停留也让人终生难忘，有些人常在身边最初感觉已不再；有些事剪断了，只盼有机会拼凑重温；有些地方用以缅怀，终也难逃土崩瓦解的时代。青春散场后，那些本以为可以抛弃的却是最根深蒂固埋藏在心的。'] ['0', '0', '1', '1', '0', '1', '0', '0', '1', '0']\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "import random\n",
    "import numpy as np\n",
    "import csv\n",
    "import jieba\n",
    "\n",
    "\n",
    "file_path = './data/review.csv'\n",
    "jieba.load_userdict(\"./data/userdict.txt\")\n",
    "\n",
    "\n",
    "def load_corpus(corpus_path):\n",
    "    with open(corpus_path, 'r') as f:\n",
    "        reader = csv.reader(f)\n",
    "        rows = [row for row in reader]\n",
    "\n",
    "    # 将读取出来的语料转为list\n",
    "    review_data = np.array(rows).tolist()\n",
    "    # 打乱语料的顺序\n",
    "    random.shuffle(review_data)\n",
    "\n",
    "    review_list = []\n",
    "    sentiment_list = []\n",
    "    # 第一列为差评/好评， 第二列为评论\n",
    "    for words in review_data:\n",
    "        review_list.append(words[1])\n",
    "        sentiment_list.append(words[0])\n",
    "\n",
    "    return review_list, sentiment_list\n",
    "\n",
    "review_list, sentiment_list = load_corpus(file_path)\n",
    "\n",
    "print(review_list[:10], sentiment_list[:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集数量： 41402\n",
      "测试集数量： 10350\n"
     ]
    }
   ],
   "source": [
    "n = len(review_list) // 5\n",
    "\n",
    "train_review_list, train_sentiment_list = review_list[n:], sentiment_list[n:]\n",
    "test_review_list, test_sentiment_list = review_list[:n], sentiment_list[:n]\n",
    "\n",
    "print('训练集数量： {}'.format(str(len(train_review_list))))\n",
    "print('测试集数量： {}'.format(str(len(test_review_list))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import jieba\n",
    "\n",
    "\n",
    "stopword_path = './data/stopwords.txt'\n",
    "\n",
    "\n",
    "def load_stopwords(file_path):\n",
    "    stop_words = []\n",
    "    with open(file_path, encoding='UTF-8') as words:\n",
    "       stop_words.extend([i.strip() for i in words.readlines()])\n",
    "    return stop_words\n",
    "\n",
    "\n",
    "def review_to_text(review):\n",
    "    stop_words = load_stopwords(stopword_path)\n",
    "    # 去除英文\n",
    "    review = re.sub(\"[^\\u4e00-\\u9fa5^a-z^A-Z]\", '', review)\n",
    "    review = jieba.cut(review)\n",
    "    # 去掉停用词\n",
    "    if stop_words:\n",
    "        all_stop_words = set(stop_words)\n",
    "        words = [w for w in review if w not in all_stop_words]\n",
    "\n",
    "    return words\n",
    "\n",
    "\n",
    "# 用于训练的评论\n",
    "review_train = [' '.join(review_to_text(review)) for review in train_review_list]\n",
    "# 对于训练评论对应的好评/差评\n",
    "sentiment_train = train_sentiment_list\n",
    "\n",
    "# 用于测试的评论\n",
    "review_test = [' '.join(review_to_text(review)) for review in test_review_list]\n",
    "# 对于测试评论对应的好评/差评\n",
    "sentiment_test = test_sentiment_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "count_vec = CountVectorizer(max_df=0.8, min_df=3)\n",
    "\n",
    "tfidf_vec = TfidfVectorizer()\n",
    "\n",
    "# 定义Pipeline对全部步骤的流式化封装和管理，可以很方便地使参数集在新数据集（比如测试集）上被重复使用。\n",
    "def MNB_Classifier():\n",
    "    return Pipeline([\n",
    "        ('count_vec', CountVectorizer()),\n",
    "        ('mnb', MultinomialNB())\n",
    "    ])\n",
    "\n",
    "mnbc_clf = MNB_Classifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "测试集准确率： 0.792463768115942\n"
     ]
    }
   ],
   "source": [
    "mnbc_clf = MNB_Classifier()\n",
    "\n",
    "# 进行训练\n",
    "mnbc_clf.fit(review_train, sentiment_train)\n",
    "\n",
    "# 测试集准确率\n",
    "print('测试集准确率： {}'.format(mnbc_clf.score(review_test, sentiment_test)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
